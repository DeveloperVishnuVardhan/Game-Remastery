{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bd/4sw518sn01v66wgf7s0j_05h0000gn/T/ipykernel_40767/2192943050.py:21: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  (720, 720), Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "# Visualize some of the results.\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "from models import SRCNN\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from utils import convert_ycbcr_to_rgb\n",
    "\n",
    "# Load the trained model.\n",
    "model = SRCNN()\n",
    "model.load_state_dict(torch.load(\"Models/Srcnn.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Load the image that we want to super-resolve.\n",
    "img_path = \"data/DIV2K_train_HR/DIV2K_train_HR/0003.png\"\n",
    "image = Image.open(img_path).convert(\"YCbCr\")\n",
    "y, cb, cr = image.split()\n",
    "\n",
    "low_res_img = y.resize(\n",
    "    (720, 720), Image.ANTIALIAS)\n",
    "upscaled_img = low_res_img.resize(\n",
    "    (y.width, y.height), Image.BICUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((720, 720), (2040, 1356))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_res_img.size, upscaled_img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms1 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((1296, 1296)),\n",
    "    # Normalizing using ImageNet stats\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jyothivishnuvardhankolla/anaconda3/envs/env_pytorch/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "original_image = transforms1(low_res_img)\n",
    "upscaled_img = transforms1(upscaled_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1296, 1296]), torch.Size([1, 1296, 1296]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_image.shape, upscaled_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the original, upscaled images.\n",
    "original_img = TF.to_pil_image(original_image)\n",
    "upscaled_img = TF.to_pil_image(upscaled_img)\n",
    "\n",
    "original_img.save('Predictions/1_original_ycrbr.png')\n",
    "upscaled_img.save('Predictions/1_bicubic_ycrbr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the original and upscaled to RGB format.\n",
    "original_cb = cb.resize(original_img.size, Image.BICUBIC)\n",
    "original_cr = cr.resize(original_img.size, Image.BICUBIC)\n",
    "\n",
    "upscaled_cb = cb.resize(upscaled_img.size, Image.BICUBIC)\n",
    "upscaled_cr = cr.resize(upscaled_img.size, Image.BICUBIC)\n",
    "\n",
    "original_rgb_image = convert_ycbcr_to_rgb(original_img, original_cb, original_cr)\n",
    "upscaled_rgb_image = convert_ycbcr_to_rgb(upscaled_img, upscaled_cb, upscaled_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_rgb_image.save('Predictions/1_original_rgb.png')\n",
    "upscaled_rgb_image.save('Predictions/1_bicubic_rgb.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms2 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((1296, 1296)),\n",
    "    # Normalizing using ImageNet stats\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def denormalize(tensor, mean, std):\n",
    "    \"\"\"\n",
    "    Denormalizes a tensor of images.\n",
    "    \n",
    "    Parameters:\n",
    "        tensor (torch.Tensor): The normalized images tensor\n",
    "        mean (list or tuple): The mean used for normalization\n",
    "        std (list or tuple): The standard deviation used for normalization\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: The denormalized images tensor\n",
    "    \"\"\"\n",
    "    for t, m, s in zip(tensor, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super-resolute the bi-cubic upscaled image.\n",
    "input_img = transforms2(upscaled_img).unsqueeze(0) # Add the batch dimension.\n",
    "\n",
    "# Super-resolve the image.\n",
    "with torch.no_grad():\n",
    "    output_img = model(input_img)\n",
    "\n",
    "# Convert the output tensor back to pil format.\n",
    "output_img = output_img.squeeze(0) # Remove the batch dimension.\n",
    "denormalized_output_img = denormalize(output_img, mean=[0.5], std=[0.5])\n",
    "output_img = TF.to_pil_image(output_img)\n",
    "\n",
    "super_resolved_cb = cb.resize(output_img.size, Image.BICUBIC)\n",
    "super_resolved_cr = cr.resize(output_img.size, Image.BICUBIC)\n",
    "super_resolved_rgb_image = convert_ycbcr_to_rgb(output_img, super_resolved_cb, super_resolved_cr)\n",
    "# Save the output_image.\n",
    "super_resolved_rgb_image.save('Predictions/SRCNN_upscaled.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
